{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from model_defs import baseline, CNN_module, CNN_module_unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "glove = torchtext.vocab.GloVe(name=\"6B\",dim=100) # embedding size = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_cnn_unf = \"models/unf_model_40_5_40_3_16_0.0001_30_5_0.9085.pt\"\n",
    "model_file_cnn = \"models/model_40_5_40_3_16_0.0001_30_0.9085.pt\"\n",
    "model_file_bs = \"models/baseline_model.pt\"\n",
    "\n",
    "model_cnn = CNN_module(glove, 40, 5, 40, 3)\n",
    "model_cnn_unf = CNN_module_unfreeze(glove, 40, 5, 40, 3)\n",
    "model_bs = baseline(glove)\n",
    "\n",
    "model_cnn.load_state_dict(torch.load(model_file_cnn))\n",
    "model_cnn_unf.load_state_dict(torch.load(model_file_cnn_unf))\n",
    "model_bs.load_state_dict(torch.load(model_file_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    tokens = sentence.split()\n",
    "    token_ints = [glove.stoi.get(tok, len(glove.stoi)-1) for tok in tokens]\n",
    "    token_tensor = torch.LongTensor(token_ints).view(-1,1)\n",
    "    # print(token_tensor)\n",
    "    # Model CNN\n",
    "    model_cnn.eval()\n",
    "    output_cnn, fc_cnn = model_cnn(token_tensor)\n",
    "    model_cnn_unf.eval()\n",
    "    output_cnn_unf, fc_cnn_unf = model_cnn_unf(token_tensor)\n",
    "    model_bs.eval()\n",
    "    prob_bs = model_bs(token_tensor)\n",
    "    output_bs = torch.sigmoid(prob_bs)\n",
    "    sub_or_ob_cnn = \"Subjective\" if output_cnn.item() > 0.5 else \"Objective\"\n",
    "    sub_or_ob_cnn_unf = \"Subjective\" if output_cnn_unf.item() > 0.5 else \"Objective\"\n",
    "    sub_or_ob_bs = \"Subjective\" if output_bs.item() > 0.5 else \"Objective\"\n",
    "    # print(\"CNN: \", sub_or_ob_cnn, output_cnn.item())\n",
    "    # print(\"CNN Unfreeze: \", sub_or_ob_cnn_unf, output_cnn_unf.item())\n",
    "    # print(\"Baseline: \", sub_or_ob_bs, output_bs.item())\n",
    "    print(\"CNN: \", sub_or_ob_cnn, output_cnn.item())\n",
    "    print(\"CNN Unfreeze: \", sub_or_ob_cnn_unf, output_cnn_unf.item())\n",
    "    print(\"Baseline: \", sub_or_ob_bs, output_bs.item())\n",
    "    return sub_or_ob_cnn, output_cnn.item(), sub_or_ob_cnn_unf, output_cnn_unf.item(), sub_or_ob_bs, output_bs.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:  Subjective 0.9999947547912598\n",
      "CNN Unfreeze:  Subjective 0.9999958276748657\n",
      "Baseline:  Subjective 0.9992876648902893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Subjective',\n",
       " 0.9999947547912598,\n",
       " 'Subjective',\n",
       " 0.9999958276748657,\n",
       " 'Subjective',\n",
       " 0.9992876648902893)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I think you are very good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "Running on public URL: https://ea58820964763ba049.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ea58820964763ba049.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:  Objective 0.02511909231543541\n",
      "CNN Unfreeze:  Objective 0.004596529062837362\n",
      "Baseline:  Subjective 0.7646906971931458\n",
      "CNN:  Subjective 0.9955385327339172\n",
      "CNN Unfreeze:  Subjective 0.9935093522071838\n",
      "Baseline:  Subjective 0.8956016302108765\n",
      "CNN:  Subjective 0.8044186234474182\n",
      "CNN Unfreeze:  Objective 0.3689664900302887\n",
      "Baseline:  Subjective 0.8043393492698669\n",
      "CNN:  Subjective 0.5382722616195679\n",
      "CNN Unfreeze:  Objective 0.39309820532798767\n",
      "Baseline:  Subjective 0.7889913320541382\n"
     ]
    }
   ],
   "source": [
    "# Gradio interface such that user can input a sentence and get the prediction and probability\n",
    "iface = gr.Interface(fn=predict, inputs=\"text\", \n",
    "                     outputs=[\"text\", \"number\", \"text\", \"number\", \"text\", \"number\"],\n",
    "                     title=\"Subjective or Objective\", \n",
    "                     description=\"Enter a sentence and the model will predict whether it is subjective or objective\")\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UofT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
